# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html
# tweets:
#   type: pandas.SQLTableDataSet
#  credentials: db_sql
#  table_name: tweets
#  load_args:
#    index_col: [index]
#  save_args:
#    if_exists: fail

tweets: 
  type: pandas.CSVDataSet
  filepath: data/01_raw/tweets.csv
  
train:
  type: pandas.CSVDataSet
  filepath: data/03_primary/train.csv

test:
  type: pandas.CSVDataSet
  filepath: data/03_primary/test.csv

train_features:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/train_features.csv

test_features:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/test_features.csv

tweets_features:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/tweets_features.csv

torch_model:
  type: csmr_kedro.extras.datasets.TorchDataSet
  model_class: csmr_kedro.models.BertSA
  filepath: data/06_models/pytorch_model.bin
  device: cpu
  load_args:
    model_params:
      predict_company: False 
      use_company: True
      company_dim: 32

model:
  type: pickle.PickleDataSet
  filepath: data/06_models/model.pkl
  
model_metrics:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataSet
  prefix: model_metrics
