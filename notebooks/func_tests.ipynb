{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733e678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:1130: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  return get_provider(package_or_requirement).get_resource_filename(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 23:11:47,047 - root - INFO - Registered hooks from 2 installed plugin(s): kedro-mlflow-0.7.2\n",
      "2021-12-27 23:11:47,048 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from kedro.framework.session import KedroSession\n",
    "from kedro.framework.session.session import _activate_session\n",
    "from kedro.framework.startup import _add_src_to_path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "project_path = current_dir.parent  # point back to the root of the project\n",
    "_add_src_to_path(project_path/\"src\", project_path)\n",
    "\n",
    "session = KedroSession.create(\"csmr_kedro\", project_path)\n",
    "_activate_session(session)\n",
    "context = session.load_context()\n",
    "catalog = context.catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558e8ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 23:12:03,320 - kedro.io.data_catalog - INFO - Loading data from `train_features` (CSVDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "      <th>text</th>\n",
       "      <th>company</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218544</td>\n",
       "      <td>-0.059096</td>\n",
       "      <td>-0.087296</td>\n",
       "      <td>0.101487</td>\n",
       "      <td>-0.080620</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.610474</td>\n",
       "      <td>-0.227217</td>\n",
       "      <td>-0.020762</td>\n",
       "      <td>-0.087030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492525</td>\n",
       "      <td>0.523683</td>\n",
       "      <td>0.133101</td>\n",
       "      <td>0.140130</td>\n",
       "      <td>-0.206967</td>\n",
       "      <td>0.260036</td>\n",
       "      <td>-0.025468</td>\n",
       "      <td>Riot é da China. As pessoas que estão acusando...</td>\n",
       "      <td>Riot Games</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125816</td>\n",
       "      <td>-0.247009</td>\n",
       "      <td>-0.036374</td>\n",
       "      <td>0.425047</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>-0.269446</td>\n",
       "      <td>0.858746</td>\n",
       "      <td>0.403927</td>\n",
       "      <td>0.332358</td>\n",
       "      <td>-0.286561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.107753</td>\n",
       "      <td>-0.070262</td>\n",
       "      <td>-0.106091</td>\n",
       "      <td>0.139984</td>\n",
       "      <td>-0.152723</td>\n",
       "      <td>-0.257614</td>\n",
       "      <td>perdao como fui vacilona ctg mas ó Aproveite m...</td>\n",
       "      <td>Magazine Luiza</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188318</td>\n",
       "      <td>-0.112590</td>\n",
       "      <td>-0.076310</td>\n",
       "      <td>0.240603</td>\n",
       "      <td>0.227864</td>\n",
       "      <td>-0.378432</td>\n",
       "      <td>0.963279</td>\n",
       "      <td>0.252382</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>-0.145545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081702</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>-0.180536</td>\n",
       "      <td>-0.360719</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>-0.285313</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>O MELIUZ TÁ DANDO 5 REAIS PARA QUE SE CADRASTR...</td>\n",
       "      <td>Magazine Luiza</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.112302</td>\n",
       "      <td>-0.103360</td>\n",
       "      <td>0.128516</td>\n",
       "      <td>0.072404</td>\n",
       "      <td>0.026124</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.314252</td>\n",
       "      <td>-0.258593</td>\n",
       "      <td>0.063542</td>\n",
       "      <td>-0.026962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401401</td>\n",
       "      <td>-0.239889</td>\n",
       "      <td>0.482421</td>\n",
       "      <td>0.084575</td>\n",
       "      <td>0.093814</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>-0.055864</td>\n",
       "      <td>@marian4emanuele amando a marvel</td>\n",
       "      <td>Marvel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197553</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>-0.115926</td>\n",
       "      <td>0.258791</td>\n",
       "      <td>0.090828</td>\n",
       "      <td>-0.347015</td>\n",
       "      <td>0.406229</td>\n",
       "      <td>0.315087</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>-0.212995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280974</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>-0.032374</td>\n",
       "      <td>-0.316548</td>\n",
       "      <td>0.152706</td>\n",
       "      <td>-0.393567</td>\n",
       "      <td>0.086916</td>\n",
       "      <td>Box \"Magisterium\" com brinde e marcadores de p...</td>\n",
       "      <td>Magazine Luiza</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>-0.086634</td>\n",
       "      <td>-0.135602</td>\n",
       "      <td>0.125128</td>\n",
       "      <td>0.107106</td>\n",
       "      <td>-0.104425</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.063315</td>\n",
       "      <td>-0.371403</td>\n",
       "      <td>0.089333</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>-0.274639</td>\n",
       "      <td>0.395577</td>\n",
       "      <td>0.134011</td>\n",
       "      <td>0.214625</td>\n",
       "      <td>0.077663</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>O que é economia comportamental? Ela explica s...</td>\n",
       "      <td>Nubank</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.005592</td>\n",
       "      <td>-0.096058</td>\n",
       "      <td>0.143292</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>-0.071264</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>0.226961</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>-0.056693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397274</td>\n",
       "      <td>-0.402100</td>\n",
       "      <td>0.411537</td>\n",
       "      <td>0.122320</td>\n",
       "      <td>0.208670</td>\n",
       "      <td>0.081014</td>\n",
       "      <td>-0.083939</td>\n",
       "      <td>Essa bolsa caindo vou pagar a fatura da nubank</td>\n",
       "      <td>Nubank</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.142003</td>\n",
       "      <td>-0.129970</td>\n",
       "      <td>-0.014842</td>\n",
       "      <td>0.098226</td>\n",
       "      <td>-0.191507</td>\n",
       "      <td>-0.049907</td>\n",
       "      <td>0.782849</td>\n",
       "      <td>0.120403</td>\n",
       "      <td>0.284153</td>\n",
       "      <td>-0.084903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187700</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.131204</td>\n",
       "      <td>-0.018337</td>\n",
       "      <td>-0.379527</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.051973</td>\n",
       "      <td>Na moral quem não gosta de X-men pra mim autom...</td>\n",
       "      <td>Marvel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>-0.056520</td>\n",
       "      <td>-0.078171</td>\n",
       "      <td>0.170138</td>\n",
       "      <td>-0.013296</td>\n",
       "      <td>-0.128705</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>0.217074</td>\n",
       "      <td>-0.253330</td>\n",
       "      <td>0.023850</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677436</td>\n",
       "      <td>-0.388043</td>\n",
       "      <td>0.465460</td>\n",
       "      <td>0.120801</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.045337</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>minha filosofia de vida agora é essa.</td>\n",
       "      <td>Nubank</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-0.003891</td>\n",
       "      <td>-0.077548</td>\n",
       "      <td>-0.157295</td>\n",
       "      <td>0.017271</td>\n",
       "      <td>0.035224</td>\n",
       "      <td>-0.063793</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>-0.086658</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816486</td>\n",
       "      <td>-0.156306</td>\n",
       "      <td>0.214593</td>\n",
       "      <td>-0.216447</td>\n",
       "      <td>-0.052137</td>\n",
       "      <td>0.053968</td>\n",
       "      <td>0.195476</td>\n",
       "      <td>Benfica falou que deu a vida na arquibancada, ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0    0.218544 -0.059096 -0.087296  0.101487 -0.080620 -0.001090  0.610474   \n",
       "1    0.125816 -0.247009 -0.036374  0.425047  0.260109 -0.269446  0.858746   \n",
       "2    0.188318 -0.112590 -0.076310  0.240603  0.227864 -0.378432  0.963279   \n",
       "3   -0.112302 -0.103360  0.128516  0.072404  0.026124  0.117978  0.314252   \n",
       "4    0.197553  0.070640 -0.115926  0.258791  0.090828 -0.347015  0.406229   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "635 -0.086634 -0.135602  0.125128  0.107106 -0.104425  0.008446 -0.063315   \n",
       "636  0.005592 -0.096058  0.143292 -0.008084 -0.071264  0.065238  0.226961   \n",
       "637  0.142003 -0.129970 -0.014842  0.098226 -0.191507 -0.049907  0.782849   \n",
       "638 -0.056520 -0.078171  0.170138 -0.013296 -0.128705  0.120502  0.217074   \n",
       "639 -0.003891 -0.077548 -0.157295  0.017271  0.035224 -0.063793  0.113228   \n",
       "\n",
       "           f8        f9       f10  ...      f762      f763      f764  \\\n",
       "0   -0.227217 -0.020762 -0.087030  ...  0.492525  0.523683  0.133101   \n",
       "1    0.403927  0.332358 -0.286561  ... -0.106895 -0.107753 -0.070262   \n",
       "2    0.252382  0.265371 -0.145545  ...  0.081702  0.137503 -0.180536   \n",
       "3   -0.258593  0.063542 -0.026962  ...  0.401401 -0.239889  0.482421   \n",
       "4    0.315087  0.439300 -0.212995  ...  0.280974  0.029056 -0.032374   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "635 -0.371403  0.089333 -0.022558  ...  0.645596 -0.274639  0.395577   \n",
       "636 -0.274313  0.055363 -0.056693  ...  0.397274 -0.402100  0.411537   \n",
       "637  0.120403  0.284153 -0.084903  ... -0.187700  0.126388  0.131204   \n",
       "638 -0.253330  0.023850 -0.000009  ...  0.677436 -0.388043  0.465460   \n",
       "639 -0.086658  0.048511  0.088610  ...  0.816486 -0.156306  0.214593   \n",
       "\n",
       "         f765      f766      f767      f768  \\\n",
       "0    0.140130 -0.206967  0.260036 -0.025468   \n",
       "1   -0.106091  0.139984 -0.152723 -0.257614   \n",
       "2   -0.360719  0.003917 -0.285313 -0.005518   \n",
       "3    0.084575  0.093814  0.027781 -0.055864   \n",
       "4   -0.316548  0.152706 -0.393567  0.086916   \n",
       "..        ...       ...       ...       ...   \n",
       "635  0.134011  0.214625  0.077663  0.054454   \n",
       "636  0.122320  0.208670  0.081014 -0.083939   \n",
       "637 -0.018337 -0.379527  0.000851 -0.051973   \n",
       "638  0.120801  0.115361  0.045337  0.013597   \n",
       "639 -0.216447 -0.052137  0.053968  0.195476   \n",
       "\n",
       "                                                  text         company  target  \n",
       "0    Riot é da China. As pessoas que estão acusando...      Riot Games     0.0  \n",
       "1    perdao como fui vacilona ctg mas ó Aproveite m...  Magazine Luiza     0.5  \n",
       "2    O MELIUZ TÁ DANDO 5 REAIS PARA QUE SE CADRASTR...  Magazine Luiza     0.5  \n",
       "3                     @marian4emanuele amando a marvel          Marvel     1.0  \n",
       "4    Box \"Magisterium\" com brinde e marcadores de p...  Magazine Luiza     0.5  \n",
       "..                                                 ...             ...     ...  \n",
       "635  O que é economia comportamental? Ela explica s...          Nubank     0.5  \n",
       "636     Essa bolsa caindo vou pagar a fatura da nubank          Nubank     0.0  \n",
       "637  Na moral quem não gosta de X-men pra mim autom...          Marvel     1.0  \n",
       "638             minha filosofia de vida agora é essa.           Nubank     0.5  \n",
       "639  Benfica falou que deu a vida na arquibancada, ...           Apple     0.5  \n",
       "\n",
       "[640 rows x 771 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.load(\"train_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705897b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 20:37:43,470 - kedro.io.data_catalog - INFO - Loading data from `torch_model` (TorchDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertSA(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): ClassificationHead(\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (company_predictor): ClassificationHead(\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       "  (company_criterion): CrossEntropyLoss()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (sa_criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.load('torch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212a7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb73fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompaniesSMReputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
